import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler

# ğŸ”¹ Charger les donnÃ©es CSV
data = pd.read_csv("data1.csv")
print("ğŸ“Š AperÃ§u des premiÃ¨res lignes :\n", data.head())

# ğŸ”¹ Encoder les labels (transformation texte -> nombre)
encoder = LabelEncoder()
data["label"] = encoder.fit_transform(data["label"])

# ğŸ”¹ VÃ©rifier l'encodage
print("\nğŸ“Œ DonnÃ©es aprÃ¨s encodage :\n", data.head())
print("ğŸ¯ Classes encodÃ©es :", dict(enumerate(encoder.classes_)))

# ğŸ”¹ Visualisation de la rÃ©partition des classes
plt.figure(figsize=(6,4))
data["label"].value_counts().plot(kind='bar', color=["skyblue", "orange"])
plt.xlabel("Classes de vibration")
plt.ylabel("Nombre d'Ã©chantillons")
plt.title("Distribution des Classes")
plt.show()

# ğŸ”¹ SÃ©parer les features (x, y, z) et les labels
X = data[['x', 'y', 'z']].values  
y = data['label'].values  

# ğŸ”¹ Normalisation des donnÃ©es (meilleur apprentissage)
scaler = StandardScaler()
X = scaler.fit_transform(X)

# ğŸ”¹ SÃ©paration en entraÃ®nement (80%) et test (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nğŸ“Œ Taille des donnÃ©es d'entraÃ®nement :", X_train.shape)
print("ğŸ“Œ Taille des donnÃ©es de test :", X_test.shape)

# ğŸ”¹ DÃ©finition du modÃ¨le de classification
model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(3,)),  # 3 entrÃ©es : x, y, z
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dropout(0.3),  # AugmentÃ© pour Ã©viter l'overfitting
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(16, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')  # Classification binaire
])

# ğŸ”¹ Compilation du modÃ¨le avec EarlyStopping
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
              loss='binary_crossentropy',
              metrics=['accuracy'])

# ğŸ”¹ Early Stopping pour Ã©viter un sur-entraÃ®nement
early_stopping = tf.keras.callbacks.EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)

# ğŸ”¹ EntraÃ®nement
history = model.fit(X_train, y_train, epochs=100, batch_size=8,
                    validation_data=(X_test, y_test), callbacks=[early_stopping])

# ğŸ”¹ Visualisation de l'apprentissage
plt.figure(figsize=(8,4))
plt.plot(history.history['loss'], label="Perte entraÃ®nement", color="blue")
plt.plot(history.history['val_loss'], label="Perte validation", color="red")
plt.xlabel("Ã‰pochs")
plt.ylabel("Perte")
plt.legend()
plt.title("Courbe de Perte du ModÃ¨le")
plt.show()

# ğŸ”¹ Convertir le modÃ¨le en TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# ğŸ”¹ Sauvegarder le modÃ¨le TFLite
with open("vibrations_model.tflite", "wb") as f:
    f.write(tflite_model)

print("\nâœ… ModÃ¨le TFLite sauvegardÃ© sous vibrations_model.tflite")

# ğŸ”¹ TÃ©lÃ©charger le modÃ¨le sur Google Colab (si nÃ©cessaire)
try:
    from google.colab import files
    files.download("vibrations_model.tflite")
except:
    print("ğŸ“Œ TÃ©lÃ©chargement ignorÃ© (exÃ©cution locale)")

# ğŸ”¹ Charger le modÃ¨le TFLite en bytes
with open("vibrations_model.tflite", "rb") as f:
    tflite_model = f.read()

# ğŸ”¹ Conversion en tableau de bytes C++ (pour Arduino)
hex_array = ", ".join("0x{:02x}".format(c) for c in tflite_model)

cpp_code = f"""
#ifndef VIBRATIONS_MODEL_H
#define VIBRATIONS_MODEL_H

alignas(8) const unsigned char vibrations_model_tflite[] = {{
    {hex_array}
}};
const int vibrations_model_tflite_len = {len(tflite_model)};

#endif  // VIBRATIONS_MODEL_H
"""

# ğŸ”¹ Sauvegarde du fichier C++ pour Arduino
with open("vibrations_model.h", "w") as f:
    f.write(cpp_code)

print("\nâœ… ModÃ¨le converti en C++ : vibrations_model.h")
